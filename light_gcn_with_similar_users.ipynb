{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb91fc0",
   "metadata" {},
   "outputs": [],
   "source": [
    "\n",
    "#  Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import save_npz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ca4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load datasets\n",
    "users_df = pd.read_csv(\"expanded_users.csv\")\n",
    "resources_df = pd.read_csv(\"expanded_resources.csv\")\n",
    "interactions_df = pd.read_csv(\"expanded_interactions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3801b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only positive interactions\n",
    "positive_df = interactions_df[interactions_df['interaction_type'].isin(['like', 'share'])].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30565362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index mappings\n",
    "user_id_map = {id_: idx for idx, id_ in enumerate(users_df['user_id'].unique())}\n",
    "resource_id_map = {id_: idx for idx, id_ in enumerate(resources_df['resource_id'].unique())}\n",
    "\n",
    "positive_df['user_index'] = positive_df['user_id'].map(user_id_map)\n",
    "positive_df['resource_index'] = positive_df['resource_id'].map(resource_id_map)\n",
    "\n",
    "num_users = len(user_id_map)\n",
    "num_items = len(resource_id_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627e735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build interaction matrix\n",
    "interaction_matrix = np.zeros((num_users, num_items), dtype=np.float32)\n",
    "for _, row in positive_df.iterrows():\n",
    "    interaction_matrix[row['user_index'], row['resource_index']] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859ca3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User features\n",
    "recovery_stage_map = {v: i for i, v in enumerate(users_df['recovery_stage'].unique())}\n",
    "preferred_type_map = {v: i for i, v in enumerate(users_df['preferred_resource_type'].unique())}\n",
    "\n",
    "users_df['recovery_stage_idx'] = users_df['recovery_stage'].map(recovery_stage_map)\n",
    "users_df['preferred_type_idx'] = users_df['preferred_resource_type'].map(preferred_type_map)\n",
    "\n",
    "user_map_df = pd.DataFrame(user_id_map.items(), columns=[\"user_id\", \"user_index\"])\n",
    "recovery_stage_indices = users_df.set_index('user_id').loc[user_map_df['user_id']]['recovery_stage_idx'].values\n",
    "preferred_type_indices = users_df.set_index('user_id').loc[user_map_df['user_id']]['preferred_type_idx'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87e55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource features\n",
    "resource_type_map = {v: i for i, v in enumerate(resources_df['resource_type'].unique())}\n",
    "resources_df['resource_type_idx'] = resources_df['resource_type'].map(resource_type_map)\n",
    "\n",
    "resource_map_df = pd.DataFrame(resource_id_map.items(), columns=[\"resource_id\", \"resource_index\"])\n",
    "resource_type_indices = resources_df.set_index('resource_id').loc[resource_map_df['resource_id']]['resource_type_idx'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c053b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCN Class Definition\n",
    "\n",
    "class LightGCNWithUserAndItemInfo(nn.Module):\n",
    "    def __init__(self, num_users, num_items, recovery_vocab, type_vocab, resource_type_vocab,\n",
    "                 embedding_dim=64, feature_dim=8, num_layers=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Base embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Side feature embeddings\n",
    "        self.recovery_embedding = nn.Embedding(recovery_vocab, feature_dim)\n",
    "        self.type_embedding = nn.Embedding(type_vocab, feature_dim)\n",
    "        self.resource_type_embedding = nn.Embedding(resource_type_vocab, feature_dim)\n",
    "\n",
    "        # Projection layers to unify dimensions\n",
    "        self.user_project = nn.Linear(embedding_dim + 2 * feature_dim, embedding_dim)\n",
    "        self.item_project = nn.Linear(embedding_dim + feature_dim, embedding_dim)\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.recovery_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.type_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.resource_type_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.user_project.weight)\n",
    "        nn.init.xavier_uniform_(self.item_project.weight)\n",
    "\n",
    "    def forward(self, adj, recovery_stage_idx, preferred_type_idx, resource_type_idx):\n",
    "        device = self.user_embedding.weight.device\n",
    "\n",
    "        # Raw base embeddings\n",
    "        user_emb = self.user_embedding.weight\n",
    "        item_emb = self.item_embedding.weight\n",
    "\n",
    "        # Side embeddings\n",
    "        recovery_emb = self.recovery_embedding(torch.tensor(recovery_stage_idx, device=device))\n",
    "        type_emb = self.type_embedding(torch.tensor(preferred_type_idx, device=device))\n",
    "        resource_type_emb = self.resource_type_embedding(torch.tensor(resource_type_idx, device=device))\n",
    "\n",
    "        # Combine + project to fixed size\n",
    "        enriched_user_emb = self.user_project(torch.cat([user_emb, recovery_emb, type_emb], dim=1))\n",
    "        enriched_item_emb = self.item_project(torch.cat([item_emb, resource_type_emb], dim=1))\n",
    "\n",
    "        user_embs = [enriched_user_emb]\n",
    "        item_embs = [enriched_item_emb]\n",
    "\n",
    "        # LightGCN message passing\n",
    "        for _ in range(self.num_layers):\n",
    "            user_emb = torch.matmul(adj, item_embs[-1])\n",
    "            item_emb = torch.matmul(adj.T, user_embs[-1])\n",
    "            user_embs.append(user_emb)\n",
    "            item_embs.append(item_emb)\n",
    "\n",
    "        return torch.stack(user_embs, dim=1).mean(dim=1), torch.stack(item_embs, dim=1).mean(dim=1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab03cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For real user input\n",
    "def recommend_for_user(self, user_id, interacted_items, top_k=5):\n",
    "\n",
    "    device = self.user_embedding.weight.device\n",
    "\n",
    "    # If user_id is new, extend embedding\n",
    "    if user_id >= self.num_users:\n",
    "        # Add a new embedding as average of existing ones\n",
    "        new_embedding = torch.mean(self.user_embedding.weight.data, dim=0, keepdim=True)\n",
    "        self.user_embedding.weight.data = torch.cat([self.user_embedding.weight.data, new_embedding], dim=0)\n",
    "        self.num_users += 1\n",
    "\n",
    "    # Forward pass to get scores\n",
    "    with torch.no_grad():\n",
    "        all_user_embeddings, all_item_embeddings = self.forward()\n",
    "\n",
    "        user_emb = all_user_embeddings[user_id]\n",
    "        scores = torch.matmul(all_item_embeddings, user_emb)\n",
    "\n",
    "        # Remove already interacted items\n",
    "        scores[interacted_items] = -float('inf')\n",
    "\n",
    "        top_scores, top_items = torch.topk(scores, top_k)\n",
    "        return top_items.cpu().numpy(), top_scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce26f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Real User Input\n",
    "\n",
    "def recommend_based_on_similar_users(self, user_id, interaction_matrix, top_k=5, num_neighbors=5):\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    device = self.user_embedding.weight.device\n",
    "    self.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_user_embeddings, all_item_embeddings = self.forward()\n",
    "\n",
    "        # Compute cosine similarity between users\n",
    "        user_emb = all_user_embeddings[user_id].unsqueeze(0)  # shape: (1, emb_dim)\n",
    "        similarities = F.cosine_similarity(user_emb, all_user_embeddings)  # shape: (num_users,)\n",
    "\n",
    "        # Get top similar users (excluding the user itself)\n",
    "        similarities[user_id] = -1  # Exclude self\n",
    "        top_users = torch.topk(similarities, num_neighbors).indices\n",
    "\n",
    "        # Get items interacted by similar users\n",
    "        sim_users_items = interaction_matrix[top_users].sum(axis=0)\n",
    "        sim_users_items = np.asarray(sim_users_items).flatten()\n",
    "\n",
    "        # Remove items already interacted by user_id\n",
    "        user_interacted = interaction_matrix[user_id].nonzero()[1]\n",
    "        sim_users_items[user_interacted] = -np.inf\n",
    "\n",
    "        # Recommend top_k items\n",
    "        top_items = np.argsort(sim_users_items)[-top_k:][::-1]\n",
    "        scores = sim_users_items[top_items]\n",
    "\n",
    "        return top_items, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b16416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.6895\n",
      "Epoch 20, Loss: 0.6846\n",
      "Epoch 30, Loss: 0.6787\n",
      "Epoch 40, Loss: 0.6716\n",
      "Epoch 50, Loss: 0.6634\n",
      "Epoch 60, Loss: 0.6557\n",
      "Epoch 70, Loss: 0.6494\n",
      "Epoch 80, Loss: 0.6419\n",
      "Epoch 90, Loss: 0.6362\n",
      "Epoch 100, Loss: 0.6290\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "adj = torch.tensor(interaction_matrix)\n",
    "adj_norm = adj / (adj.sum(dim=1, keepdim=True) + 1e-10)\n",
    "adj_norm = adj_norm.float()\n",
    "\n",
    "model = LightGCNWithUserAndItemInfo(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    recovery_vocab=len(recovery_stage_map),\n",
    "    type_vocab=len(preferred_type_map),\n",
    "    resource_type_vocab=len(resource_type_map)\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    user_emb, item_emb = model(\n",
    "        adj_norm,\n",
    "        recovery_stage_indices,\n",
    "        preferred_type_indices,\n",
    "        resource_type_indices\n",
    "    )\n",
    "\n",
    "    pos_u = torch.tensor(positive_df['user_index'].values)\n",
    "    pos_i = torch.tensor(positive_df['resource_index'].values)\n",
    "    neg_i = torch.randint(0, num_items, pos_i.shape)\n",
    "\n",
    "    pos_scores = (user_emb[pos_u] * item_emb[pos_i]).sum(dim=1)\n",
    "    neg_scores = (user_emb[pos_u] * item_emb[neg_i]).sum(dim=1)\n",
    "\n",
    "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b735317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Metrics\n",
    "\n",
    "def precision_at_k(actual, predicted, k):\n",
    "    return len(set(actual) & set(predicted[:k])) / float(k)\n",
    "\n",
    "def recall_at_k(actual, predicted, k):\n",
    "    return len(set(actual) & set(predicted[:k])) / float(len(actual)) if actual else 0.0\n",
    "\n",
    "def dcg_at_k(relevance, k):\n",
    "    relevance = np.array(relevance)[:k]\n",
    "    return np.sum((2 ** relevance - 1) / np.log2(np.arange(2, 2 + len(relevance))))\n",
    "\n",
    "def ndcg_at_k(actual, predicted, k):\n",
    "    relevance = [1 if item in actual else 0 for item in predicted[:k]]\n",
    "    ideal_relevance = sorted(relevance, reverse=True)\n",
    "    dcg = dcg_at_k(relevance, k)\n",
    "    idcg = dcg_at_k(ideal_relevance, k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def f1_at_k(precision, recall):\n",
    "    return 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a51075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Recommendations for U0006:\n",
      "R0765\n",
      "R0167\n",
      "R0203\n",
      "R0671\n",
      "R0065\n",
      "R0595\n",
      "R0968\n",
      "R0598\n",
      "R0231\n",
      "R0691\n",
      "R0824\n",
      "R0571\n",
      "R0962\n",
      "R0947\n",
      "R0504\n",
      "R0853\n",
      "R0354\n",
      "R0652\n",
      "R0928\n",
      "R0073\n",
      "\n",
      "Evaluation for user U0006\n",
      "Precision@20: 0.6500\n",
      "Recall@20:    0.0394\n",
      "NDCG@20:      0.9554\n",
      "F1@20:        0.0743\n"
     ]
    }
   ],
   "source": [
    "# Recommendation and Evaluation for a User\n",
    "\n",
    "target_user_id = 'U0006'\n",
    "target_index = user_id_map[target_user_id]\n",
    "\n",
    "model.eval()\n",
    "user_emb, item_emb = model(\n",
    "    adj_norm,\n",
    "    recovery_stage_indices,\n",
    "    preferred_type_indices,\n",
    "    resource_type_indices\n",
    ")\n",
    "\n",
    "scores = torch.matmul(user_emb[target_index], item_emb.T)\n",
    "predicted_indices = scores.argsort(descending=True).tolist()\n",
    "actual_items = positive_df[positive_df['user_index'] == target_index]['resource_index'].tolist()\n",
    "\n",
    "K = 20\n",
    "prec = precision_at_k(actual_items, predicted_indices, K)\n",
    "rec = recall_at_k(actual_items, predicted_indices, K)\n",
    "ndcg = ndcg_at_k(actual_items, predicted_indices, K)\n",
    "f1 = f1_at_k(prec, rec)\n",
    "\n",
    "print(f\"\\nTop {K} Recommendations for {target_user_id}:\")\n",
    "for i in predicted_indices[:K]:\n",
    "    print(resource_map_df[resource_map_df['resource_index'] == i]['resource_id'].values[0])\n",
    "\n",
    "print(f\"\\nEvaluation for user {target_user_id}\")\n",
    "print(f\"Precision@{K}: {prec:.4f}\")\n",
    "print(f\"Recall@{K}:    {rec:.4f}\")\n",
    "print(f\"NDCG@{K}:      {ndcg:.4f}\")\n",
    "print(f\"F1@{K}:        {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2c29f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 similar users to U0006:\n",
      "U0079\n",
      "U0578\n",
      "U0209\n",
      "U0866\n",
      "U0862\n"
     ]
    }
   ],
   "source": [
    "#User Similarity\n",
    "\n",
    "# Get final user embeddings\n",
    "model.eval()\n",
    "user_emb, item_emb = model(\n",
    "    adj_norm,\n",
    "    recovery_stage_indices,\n",
    "    preferred_type_indices,\n",
    "    resource_type_indices\n",
    ")\n",
    "\n",
    "# Convert to NumPy for similarity\n",
    "user_emb_np = user_emb.detach().cpu().numpy()\n",
    "similarity_matrix = cosine_similarity(user_emb_np)\n",
    "\n",
    "# 🔍 Target user\n",
    "target_user_id = 'U0006'\n",
    "target_index = user_id_map[target_user_id]\n",
    "\n",
    "# Get top 5 similar users (excluding self)\n",
    "similar_users_idx = np.argsort(-similarity_matrix[target_index])[1:6]\n",
    "\n",
    "print(f\"\\nTop 5 similar users to {target_user_id}:\")\n",
    "for idx in similar_users_idx:\n",
    "    print([k for k, v in user_id_map.items() if v == idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "533c4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Evaluation\n",
    "\n",
    "def global_evaluation(\n",
    "        model, \n",
    "        adj_norm,\n",
    "        user_id_map, \n",
    "        resource_id_map,\n",
    "        recovery_stage_indices, \n",
    "        preferred_type_indices, \n",
    "        resource_type_indices,\n",
    "        positive_df, \n",
    "        K=20):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Get final user and item embeddings\n",
    "    user_emb, item_emb = model(\n",
    "        adj_norm,\n",
    "        recovery_stage_indices,\n",
    "        preferred_type_indices,\n",
    "        resource_type_indices\n",
    "    )\n",
    "\n",
    "    precisions, recalls, ndcgs, f1s = [], [], [], [] \n",
    "\n",
    "    for user_id, user_index in user_id_map.items():\n",
    "        actual_items = positive_df[positive_df['user_index'] == user_index]['resource_index'].tolist()\n",
    "        if len(actual_items) == 0:\n",
    "            continue  # Skip users with no data\n",
    "\n",
    "        scores = torch.matmul(user_emb[user_index], item_emb.T)\n",
    "        predicted_indices = scores.argsort(descending=True).tolist()\n",
    "\n",
    "        prec = precision_at_k(actual_items, predicted_indices, K)\n",
    "        rec = recall_at_k(actual_items, predicted_indices, K)\n",
    "        ndcg = ndcg_at_k(actual_items, predicted_indices, K)\n",
    "        f1 = f1_at_k(prec, rec)\n",
    "        hit = int(len(set(actual_items) & set(predicted_indices[:K])))\n",
    "\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        ndcgs.append(ndcg)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    print(f\"\\nGlobal Evaluation (K={K}) across {len(precisions)} users:\")\n",
    "    print(f\"Precision@{K}: {np.mean(precisions):.4f}\")\n",
    "    print(f\"Recall@{K}:    {np.mean(recalls):.4f}\")\n",
    "    print(f\"NDCG@{K}:      {np.mean(ndcgs):.4f}\")\n",
    "    print(f\"F1@{K}:        {np.mean(f1s):.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe6ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global Evaluation (K=20) across 1000 users:\n",
      "Precision@20: 0.5482\n",
      "Recall@20:    0.0330\n",
      "NDCG@20:      0.8052\n",
      "F1@20:        0.0622\n"
     ]
    }
   ],
   "source": [
    "#Global Evaluation across all users\n",
    "\n",
    "global_evaluation(\n",
    "    model=model,\n",
    "    adj_norm=adj_norm,\n",
    "    user_id_map=user_id_map,\n",
    "    resource_id_map=resource_id_map,\n",
    "    recovery_stage_indices=recovery_stage_indices,\n",
    "    preferred_type_indices=preferred_type_indices,\n",
    "    resource_type_indices=resource_type_indices,\n",
    "    positive_df=positive_df,\n",
    "    K=20  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee124e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba01bc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightgcn_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save interaction matrix\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43msave_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minteraction_matrix.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteraction_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel and interaction matrix saved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\_matrix_io.py:58\u001b[0m, in \u001b[0;36msave_npz\u001b[1;34m(file, matrix, compressed)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Save a sparse matrix or array to a file using ``.npz`` format.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m       [4, 0, 0]], dtype=int64)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m arrays_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmatrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbsr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     59\u001b[0m     arrays_dict\u001b[38;5;241m.\u001b[39mupdate(indices\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mindices, indptr\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mindptr)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m matrix\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdia\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save model\n",
    "torch.save(model, \"lightgcn_model.pt\")\n",
    "\n",
    "# Save interaction matrix\n",
    "save_npz(\"interaction_matrix.npz\", interaction_matrix)\n",
    "\n",
    "print(\"Model and interaction matrix saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
